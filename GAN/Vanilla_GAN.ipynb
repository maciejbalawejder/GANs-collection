{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a358e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dropout, BatchNormalization as BN, LeakyReLU, Flatten, Dense, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from google.colab import drive\n",
    "from tqdm import tqdm\n",
    "from google.colab import files\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(name, index): \n",
    "    (xtest, ytest), (xtrain, ytrain) = name.load_data()\n",
    "    dataset = np.vstack((xtest,xtrain))\n",
    "    label = np.vstack((ytest.reshape(ytest.shape[0],1),ytrain.reshape(ytrain.shape[0],1))).reshape(dataset.shape[0],)\n",
    "    dataset = (dataset[np.where(label == index)] - 127.5).astype(np.float32) / 127.5\n",
    "    return dataset\n",
    "\n",
    "fashion_dataset = data(fashion_mnist,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self, lr, input_shape):\n",
    "        self.lr = lr\n",
    "        self.input_shape = input_shape\n",
    "        self.d = self.model() \n",
    "        \n",
    "    def model(self):\n",
    "        Model = Sequential()\n",
    "        Model.add(Conv2D(filters = 64, kernel_size = (5,5), strides = (2,2), padding = 'same', input_shape = self.input_shape))\n",
    "        Model.add(LeakyReLU(alpha = 0.2))\n",
    "        Model.add(Dropout(0.3))        \n",
    "        \n",
    "        Model.add(Conv2D(filters = 128, kernel_size = (5,5), strides = (2,2), padding = 'same'))\n",
    "        Model.add(LeakyReLU(alpha = 0.2))\n",
    "        Model.add(Dropout(0.3))        \n",
    "        \n",
    "        Model.add(Flatten())\n",
    "        \n",
    "        Model.add(Dense(1, activation = 'sigmoid'))\n",
    "        Model.compile(optimizer = Adam(lr = self.lr, beta_1 = 0.5), loss = 'binary_crossentropy')\n",
    "        \n",
    "        print(Model.summary())\n",
    "\n",
    "        return Model\n",
    "    \n",
    "        \n",
    "class Generator:\n",
    "    def __init__(self, lr, input_shape, latent_dim):\n",
    "        self.lr = lr\n",
    "        self.latent_dim = latent_dim \n",
    "        self.output_shape = input_shape\n",
    "        self.g = self.model()\n",
    "        \n",
    "    def model(self):\n",
    "        Model = Sequential()\n",
    "        Model.add(Dense(7*7*self.latent_dim, input_dim = self.latent_dim))\n",
    "        Model.add(LeakyReLU(alpha = 0.2))\n",
    "        Model.add(Reshape((7,7,self.latent_dim)))\n",
    "        \n",
    "        Model.add(Conv2DTranspose(128, kernel_size = (5,5), strides = (2,2), padding = 'same'))\n",
    "        Model.add(BN())\n",
    "        Model.add(LeakyReLU(alpha = 0.2))\n",
    "\n",
    "        Model.add(Conv2DTranspose(64, kernel_size = (4,4), strides = (2,2), padding = 'same'))\n",
    "        Model.add(BN())\n",
    "        Model.add(LeakyReLU(alpha = 0.2))\n",
    "\n",
    "        Model.add(Conv2DTranspose(1, kernel_size = (3,3), padding = 'same', activation = 'tanh'))   \n",
    "        Model.add(Flatten())\n",
    "        Model.add(Reshape(self.output_shape))\n",
    "        \n",
    "        print(Model.summary())\n",
    "        \n",
    "        return Model\n",
    "    \n",
    "    \n",
    "class GAN:\n",
    "    def __init__(self, dataset, epochs = 1000, batch = 64, latent_dim = 128, lr = 2e-4):\n",
    "        self.epochs = epochs \n",
    "        self.batch = batch \n",
    "        self.latent_dim = latent_dim\n",
    "        self.lr = lr \n",
    "        self.dataset = dataset.reshape(*dataset.shape, 1)\n",
    "        self.input_size = (self.dataset[0].shape[0], self.dataset[0].shape[1], 1)\n",
    "        self.half_batch = self.batch // 2\n",
    "        \n",
    "        \n",
    "        self.D = Discriminator(self.lr, self.input_size).d\n",
    "        self.G = Generator(self.lr, self.input_size, self.latent_dim).g\n",
    "        self.GAN_model = self.gan_model()\n",
    "        \n",
    "        self.DLoss = []\n",
    "        self.GLoss = []\n",
    "        self.images = self.stack()\n",
    "        self.real = []\n",
    "        self.fake = []\n",
    "\n",
    "        \n",
    "    def gan_model(self):\n",
    "        self.D.trainable = False\n",
    "        \n",
    "        Model = Sequential()\n",
    "        Model.add(self.G)\n",
    "        Model.add(self.D)\n",
    "        Model.compile(optimizer = Adam(lr = self.lr, beta_1 = 0.5), loss = 'binary_crossentropy')\n",
    "        return Model \n",
    "    \n",
    "    def z(self,batch):\n",
    "        return np.random.uniform(-1,1,(batch,self.latent_dim)).reshape(batch,1,1,self.latent_dim)\n",
    "    \n",
    "    def stack(self, size = 15): \n",
    "        imgs = self.G.predict(self.z(size))\n",
    "        stacked = imgs[0]\n",
    "        for i in range(1,size): \n",
    "            stacked = np.vstack((stacked, imgs[i]))\n",
    "            \n",
    "        return stacked\n",
    "    \n",
    "    def plot(self, epoch, size = 5):\n",
    "        for i in range(size**2):\n",
    "            plt.subplot(size,size,i + 1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(self.G.predict(self.z(1)).reshape(28,28),cmap = 'gray')\n",
    "        plt.savefig('img{}.png'.format(epoch), dpi = 400)\n",
    "        files.download('img{}.png'.format(epoch))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def loss_graph(self, epoch):\n",
    "        x = [i for i in range(len(self.GLoss))]\n",
    "        plt.plot(x,self.GLoss, color = 'b', label = 'Generator')\n",
    "        plt.plot(x,self.DLoss, color = 'y', label = 'Discriminator')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.savefig('graph.png',dpi = 400)\n",
    "        plt.imsave('img{}.png'.format(epoch),self.images.reshape(self.images.shape[0],self.images.shape[1]), cmap = 'gray', dpi = 400)\n",
    "        files.download('img{}.png'.format(epoch))\n",
    "        files.download('graph.png')\n",
    "\n",
    "\n",
    "    def train(self): \n",
    "        for epoch in tqdm(range(1, self.epochs+1), ascii = True, unit = 'Epoch'):\n",
    "        \n",
    "            if np.random.random() > 0.05:\n",
    "                real_labels = np.random.uniform(0.9,1,self.half_batch).reshape(self.half_batch,1)\n",
    "                fake_labels = np.random.uniform(0,0.2,self.half_batch).reshape(self.half_batch,1)\n",
    "\n",
    "            else:\n",
    "                fake_labels = np.random.uniform(0.9,1,self.half_batch).reshape(self.half_batch,1)\n",
    "                real_labels = np.zeros((self.half_batch,1)).reshape(self.half_batch,1)\n",
    "                                                                               \n",
    "            real_imgs = self.dataset[np.random.randint(0,len(self.dataset), self.half_batch)]\n",
    "            real_loss = self.D.train_on_batch(real_imgs,real_labels)\n",
    "            \n",
    "            fake_imgs = self.G.predict(self.z(self.half_batch))\n",
    "            fake_loss = self.D.train_on_batch(fake_imgs, fake_labels)\n",
    "            \n",
    "            DL = 0.5 * (real_loss + fake_loss)\n",
    "            self.DLoss.append(DL)\n",
    "            \n",
    "            #-----------------------------------------------------#\n",
    "            \n",
    "            noise = self.z(self.batch)\n",
    "            labels = np.random.uniform(0.9,1,self.batch)\n",
    "            GL = self.GAN_model.train_on_batch(noise,labels)\n",
    "            self.GLoss.append(GL)\n",
    "            \n",
    "            #-----------------------------------------------------#\n",
    "            \n",
    "            if epoch%(self.epochs//50) == 0:\n",
    "                self.images = np.hstack((self.images,self.stack()))\n",
    "                if epoch > self.epochs // 2: \n",
    "                    self.G.save('model{}.h5'.format(epoch))\n",
    "            \n",
    "            if epoch % 100 == 0 and epoch > 0.5 * self.epochs: \n",
    "                self.plot(epoch)\n",
    "            \n",
    "        self.loss_graph(epoch)\n",
    "              \n",
    "                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
